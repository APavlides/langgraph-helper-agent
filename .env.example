# LangGraph Helper Agent - Environment Variables
# Copy this file to .env and fill in your values

# === Required ===

# Google API Key (for Gemini LLM and embeddings)
# Get yours at: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=your_google_api_key_here

# === Required for Online Mode ===

# Tavily API Key (for web search in online mode)
# Get yours at: https://tavily.com/ (free tier available)
TAVILY_API_KEY=your_tavily_api_key_here

# === Optional ===

# Operating mode: "offline" or "online"
# Can also be set via --mode CLI flag
AGENT_MODE=offline

# LLM model to use
# Options: gemini-1.5-flash, gemini-1.5-pro, gemini-2.0-flash-exp
LLM_MODEL=gemini-1.5-flash

# Embedding model
EMBEDDING_MODEL=models/embedding-001

# Temperature for LLM responses (0.0 - 1.0)
TEMPERATURE=0.1

# Number of documents to retrieve
RETRIEVAL_K=5

# Chunk size for document splitting
CHUNK_SIZE=1000

# Overlap between chunks
CHUNK_OVERLAP=200

# Confidence threshold for web search trigger (online mode)
# Below this threshold, web search is performed
CONFIDENCE_THRESHOLD=0.7

# Maximum web search results to fetch
MAX_WEB_RESULTS=3

# Data directory path
DATA_DIR=data

# LangGraph Helper Agent - Environment Variables

# === Ollama Configuration (Required) ===

# LLM model to use (for Ollama)
# Pull models with: ollama pull <model>
# Recommended: llama3.2:3b (2GB), llama3.2:7b (4GB)
LLM_MODEL=llama3.2:3b

# Embedding model (for Ollama)
# Pull with: ollama pull nomic-embed-text
EMBEDDING_MODEL=nomic-embed-text

# Ollama server base URL
# macOS/Windows: http://host.docker.internal:11434
# Linux: http://localhost:11434
OLLAMA_BASE_URL=http://host.docker.internal:11434

# === Online Mode (Optional) ===

# Tavily API Key (for web search in online mode)
# Get yours at: https://tavily.com/ (free tier: 1000 searches/month)
TAVILY_API_KEY=your_tavily_api_key_here

# === RAGAS Evaluation (Optional) ===

# Google Gemini API Key (only for RAGAS evaluation metrics)
# Get yours at: https://aistudio.google.com/app/apikey
# Free tier: 1500 requests/day
# Note: NOT used for agent queries, only for evaluation
GOOGLE_API_KEY=your_google_api_key_here

# === Agent Configuration ===

# Operating mode: "offline" (local docs only) or "online" (+ web search)
AGENT_MODE=offline

# Number of documents to retrieve
RETRIEVAL_K=5

# Chunk size for document splitting
CHUNK_SIZE=1000

# Overlap between chunks
CHUNK_OVERLAP=200

# Confidence threshold for web search trigger (online mode)
# Below this threshold, web search is performed
CONFIDENCE_THRESHOLD=0.7

# Maximum web search results to fetch
MAX_WEB_RESULTS=3

# Data directory path
DATA_DIR=data
